---
title: "Gradient Descent. Convergence rates"
author: Daniil Merkulov
institute: Optimization methods. MIPT
# bibliography: ../../files/biblio.bib
# csl: ../../files/diabetologia.csl
format: 
    beamer:
        pdf-engine: pdflatex
        aspectratio: 169
        fontsize: 9pt
        section-titles: false
        incremental: true
        include-in-header: ../../files/header.tex  # Custom LaTeX commands and preamble
---

# Recap

## Previously

:::: {.columns}
::: {.column width="80%"}

* Gradient Descent
* Steepest descent
* Convergence rates (no proof)
* If $f: \mathbb{R}^d \to \mathbb{R}$ is $L$-smooth then for all $x,y \in \mathbb{R}^d$ 
    
    $$
    f(y) \leq f(x) + \langle \nabla f(x), y-x \rangle +\frac{L}{2} \|y-x\|^2.
    $$

* Let $f:\mathbb{R}^d \to \mathbb{R}$ be a twice differentiable $L$-smooth function. Then, for all $x \in \mathbb{R}^d$, for every eigenvalue $\lambda$ of $\nabla^2 f(x)$, we have 
    $$
    \vert \lambda \vert \leq L.
    $$

:::
::: {.column width="20%"}

![Steepest Descent](GD_vs_Steepest.pdf)

[Open In Colab $\clubsuit$](https://colab.research.google.com/github/MerkulovDaniil/optim/blob/master/assets/Notebooks/Steepest_descent.ipynb)
:::
::::

# Convergence proofs

## Convergence rates

$$
\min_{x \in \mathbb{R}^n} f(x) \qquad \qquad x_{k+1} = x_k - \alpha_k \nabla f(x_k)
$$

|smooth | convex | smooth & convex | smooth & strongly convex (or PL) |
|:-----:|:-----:|:-----:|:--------:|
| $\|\nabla f(x_k)\|^2 \approx \mathcal{O} \left( \dfrac{1}{k} \right)$ | $f(x_k) - f^* \approx  \mathcal{O} \left( \dfrac{1}{\sqrt{k}} \right)$  | $f(x_k) - f^* \approx  \mathcal{O} \left( \dfrac{1}{k} \right)$ | $\|x_k - x^*\|^2 \approx \mathcal{O} \left( \left(1 - \dfrac{\mu}{L}\right)^k \right)$ |

## Coordinate shift for strongly convex quadratics

:::: {.columns}

::: {.column width="70%"}

Consider the following quadratic optimization problem:

$$
\label{problem}
\min\limits_{x \in \mathbb{R}^d} f(x) =  \min\limits_{x \in \mathbb{R}^d} \dfrac{1}{2} x^\top  A x - b^\top  x + c, \text{ where }A \in \mathbb{S}^d_{++}.
$$

. . .

* Firstly, without loss of generality we can set $c = 0$, which will or affect optimization process.
* Secondly, we have a spectral decomposition of the matrix $A$: 
    $$
    A = Q \Lambda Q^T
    $$
* Let's show, that we can switch coordinates in order to make an analysis a little bit easier. Let $\hat{x} = Q^T(x - x^*)$, where $x^*$ is the minimum point of initial function, defined by $Ax^* = b$. At the same time $x = Q\hat{x} + x^*$.
    $$
    \begin{split}
    \uncover<+->{ f(\hat{x}) &= \frac12  (Q\hat{x} + x^*)^\top  A (Q\hat{x} + x^*) - b^\top  (Q\hat{x} + x^*) \\}
    \uncover<+->{ &= \frac12 \hat{x}^T Q^TAQ\hat{x} + (x^*)^TAQ\hat{x} + \frac12 (x^*)^T A (x^*)^T - b^T Q\hat{x} - b^T x^*\\}
    \uncover<+->{ &=  \frac12 \hat{x}^T \Lambda \hat{x}}
    \end{split}
    $$

:::
::: {.column width="30%"}
![](coordinate_shift.pdf)
:::
::::

## Strongly convex quadratics

Now we can work with the function $f(x) = \frac12 x^T \Lambda x$ with $x^* = 0$ without loss of generality (drop the hat from the $\hat{x}$)

:::: {.columns}
::: {.column width="50%"}
$$
\begin{split}
\uncover<+->{x^{k+1} &= x^k - \alpha^k \nabla f(x^k)} 
\uncover<+->{= x^k - \alpha^k \Lambda x^k \\ } 
\uncover<+->{&= (I - \alpha^k \Lambda) x^k \\ }
\uncover<+->{ x^{k+1}_{(i)} &= (1 - \alpha^k \lambda_{(i)}) x^k_{(i)} \text{ For $i$-th coordinate} \\ }
\uncover<+->{  x^{k+1}_{(i)} &= (1 - \alpha^k \lambda_{(i)})^k x^0_{(i)}}
\end{split}
$$
\uncover<+->{
Let's use constant stepsize $\alpha^k = \alpha$. Convergence condition:
$$
\rho(\alpha) = \max_{i} |1 - \alpha \lambda_{(i)}| < 1
$$
Remember, that $\lambda_{\text{min}} = \mu > 0, \lambda_{\text{max}} = L \geq \mu$.}

:::: {.columns}
::: {.column width="50%"}
$$
\begin{split}
\uncover<+->{ |1 - \alpha \mu| &< 1 \\ }
\uncover<+->{ -1 < 1 &- \alpha \mu < 1 \\ }
\uncover<+->{ \alpha < \frac{2}{\mu} \quad & \quad \alpha\mu > 0}
\end{split}
$$
:::
::: {.column width="50%"}
$$
\begin{split}
\uncover<+->{ |1 - \alpha L| &< 1 \\ }
\uncover<+->{ -1 < 1 &- \alpha L < 1 \\ }
\uncover<+->{ \alpha < \frac{2}{L} \quad & \quad \alpha L > 0}
\end{split}
$$
:::
::::

. . .

$\alpha < \frac{2}{L}$ is needed for convergence.

:::

. . .

::: {.column width="50%"}
Now we would like to choose $\alpha$ in order to choose the best (lowest) convergence rate

$$
\begin{split}
\uncover<+->{ \rho^* &=  \min_{\alpha} \rho(\alpha) } \uncover<+->{  = \min_{\alpha} \max_{i} |1 - \alpha \lambda_{(i)}| \\ }
\uncover<+->{ &=  \min_{\alpha} \left\{|1 - \alpha \mu|, |1 - \alpha L| \right\} \\ }
\uncover<+->{ \alpha^* &: \quad  1 - \alpha^* \mu = \alpha^* L - 1 \\ }
\uncover<+->{ & \alpha^* = \frac{2}{\mu + L} } \uncover<+->{ \quad \rho^* = \frac{L - \mu}{L + \mu} \\ }
\uncover<+->{ x^{k+1} &= \left( \frac{L - \mu}{L + \mu} \right)^k x^0 } \uncover<+->{ \quad f(x^{k+1}) = \left( \frac{L - \mu}{L + \mu} \right)^{2k} f(x^0)}
\end{split}
$$
:::
::::

## Strongly convex quadratics

So, we have a linear convergence in domain with rate $\frac{\kappa - 1}{\kappa + 1} = 1 - \frac{2}{\kappa + 1}$, where $\kappa = \frac{L}{\mu}$ is sometimes called *condition number* of the quadratic problem.

| $\kappa$ | $\rho$ | Iterations to decrease domain gap $10$ times | Iterations to decrease function gap $10$ times |
|:-:|:-:|:-----------:|:-----------:|
| $1.1$ | $0.05$ | $1$ | $1$ |
| $2$ | $0.33$ | $3$ | $2$ |
| $5$ | $0.67$ | $6$ | $3$ |
| $10$ | $0.82$ | $12$ | $6$ |
| $50$ | $0.96$ | $58$ | $29$ |
| $100$ | $0.98$ | $116$ | $58$ |
| $500$ | $0.996$ | $576$ | $288$ |
| $1000$ | $0.998$ | $1152$ | $576$ |

## Polyak- Lojasiewicz condition. Linear convergence of gradient descent without convexity

PL inequality holds if the following condition is satisfied for some $\mu > 0$,
$$
\Vert \nabla f(x) \Vert^2 \geq 2 \mu (f(x) - f^*) \quad \forall x
$$
It is interesting, that Gradient Descent algorithm has

The following functions satisfy the PL-condition, but are not convex. [\faPython Link to the code](https://colab.research.google.com/github/MerkulovDaniil/optim/blob/master/assets/Notebooks/PL_function.ipynb)

:::: {.columns}

::: {.column width="50%"}

$$
f(x) = x^2 + 3\sin^2(x)
$$

![PL function](pl_2d.pdf){width=65%}

:::

. . .

::: {.column width="50%"}

$$
f(x,y) = \dfrac{(y - \sin x)^2}{2}
$$

![PL function](pl_3d.pdf){width=80%}

:::
::::

## Gradient Descent convergence. Polyak-Lojasiewicz case

:::{.callout-theorem}
Consider the Problem 

$$
f(x) \to \min_{x \in \mathbb{R}^d}
$$

and assume that $f$ is $\mu$-Polyak-Åojasiewicz and $L$-smooth, for some $L\geq \mu >0$.

Consider $(x^t)_{t \in \mathbb{N}}$ a sequence generated by the gradient descent constant stepsize algorithm, with a stepsize satisfying $0<\alpha \leq \frac{1}{L}$. Then:

$$
f(x^{t})-f^* \leq (1-\alpha \mu)^t (f(x^0)-f^*).
$$
:::

## Gradient Descent convergence. Polyak-Lojasiewicz case

We can use $L$-smoothness, together with the update rule of the algorithm, to write

$$
\begin{split}
f(x^{t+1})& \leq   f(x^{t}) + \langle \nabla f(x^t), x^{t+1}-x^t \rangle +\frac{L}{2} \| x^{t+1}-x^t\|^2\\
&= f(x^{t})-\alpha\Vert \nabla f(x^t) \Vert^2 +\frac{L \alpha^2}{2} \| \nabla f(x^t)\|^2 \\
&= f(x^{t}) - \frac{\alpha}{2} \left(2 - L \alpha \right)\Vert \nabla f(x^t) \Vert^2 \\
& \leq f(x^{t}) - \frac{\alpha}{2}\Vert \nabla f(x^t)\Vert^2,
\end{split}
$$

where in the last inequality we used our hypothesis on the stepsize that $\alpha L \leq 1$.

. . .

We can now use the Polyak-Lojasiewicz property to write:

$$
f(x^{t+1}) \leq f(x^{t}) - \alpha \mu (f(x^t) - f^*).
$$

The conclusion follows after subtracting $f^*$ on both sides of this inequality, and using recursion.

## Gradient Descent convergence. Smooth convex case

:::{.callout-theorem}
Consider the Problem 

$$
f(x) \to \min_{x \in \mathbb{R}^d}
$$

and assume that $f$ is convex and $L$-smooth, for some $L>0$.

Let $(x^t)_{t \in \mathbb{N}}$ be the sequence of iterates generated by the gradient descent constant stepsize algorithm, with a stepsize satisfying $0 < \alpha\leq \frac{1}{L}$. Then, for all $x^* \in {\rm{argmin}}~f$, for all $t \in \mathbb{N}$ we have that

$$
f(x^t)-f^* \leq \frac{\|x^0-x^*\| ^2}{2 \alpha t}.
$$
:::

## Gradient Descent convergence. Smooth convex case

## Gradient Descent convergence. Smooth $\mu$-strongly convex case

:::{.callout-theorem}
Consider the Problem 

$$
f(x) \to \min_{x \in \mathbb{R}^d}
$$

and assume that $f$ is $\mu$-strongly convex and $L$-smooth, for some $L\geq \mu >0$.
Let $(x^t)_{t \in \mathbb{N}}$ be the sequence of iterates generated by the gradient descent constant stepsize algorithm, with a stepsize satisfying $0 < \alpha\leq \frac{1}{L}$. Then, for $x^* = {\rm{argmin}}~f$ and for all $t \in \mathbb{N}$:

$$
\|x^{t+1}-x^*\|^2 \leq (1-\alpha \mu)^{t+1} \|x^0 -x^*\|^2.
$$
:::

## Gradient Descent convergence. Smooth $\mu$-strongly convex case

## Gradient Descent for Linear Least Squares aka Linear Regression

![Illustration](lls_idea.pdf){width=75%}

In a least-squares, or linear regression, problem, we have measurements $X \in \mathbb{R}^{m \times n}$ and $y \in \mathbb{R}^{m}$ and seek a vector $\theta \in \mathbb{R}^{n}$ such that $X \theta$ is close to $y$. Closeness is defined as the sum of the squared differences: 

$$ 
\sum\limits_{i=1}^m (x_i^\top \theta - y_i)^2 = \|X \theta - y\|^2_2 \to \min_{\theta \in \mathbb{R}^{n}}
$$

For example, we might have a dataset of $m$ users, each represented by $n$ features. Each row $x_i^\top$ of $X$ is the features for user $i$, while the corresponding entry $y_i$ of $y$ is the measurement we want to predict from $x_i^\top$, such as ad spending. The prediction is given by $x_i^\top \theta$.

## Linear Least Squares aka Linear Regression ^[Take a look at the [\faPython  example](https://colab.research.google.com/github/MerkulovDaniil/optim/blob/master/assets/Notebooks/Real_world_LLS_exercise.ipynb) of real-world data linear least squares problem]

1. Is this problem convex? Strongly convex?
1. What do you think about convergence of Gradient Descent for this problem?

## $l_2$-regularized Linear Least Squares

In the underdetermined case, it is often desirable to restore strong convexity of the objective function by adding an $l_2$-penality, also known as Tikhonov regularization, $l_2$-regularization, or weight decay.

$$
\|X \theta - y\|^2_2  + \dfrac{\mu}{2} \|\theta\|^2_2\to \min_{\theta \in \mathbb{R}^{n}}
$$

Note: With this modification the objective is $\mu$-strongly convex again.

Take a look at the [\faPython code](https://colab.research.google.com/github/MerkulovDaniil/optim/blob/master/assets/Notebooks/l2_LLS.ipynb)

